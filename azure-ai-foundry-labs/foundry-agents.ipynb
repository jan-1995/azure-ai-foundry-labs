{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !\"C:/Users/HaiderJan/OneDrive - Royal Cyber Inc/Desktop/Azure/.venv/Scripts/python.exe\" -m pip install --upgrade azure-core\n",
    "!\"C:/Users/HaiderJan/OneDrive - Royal Cyber Inc/Desktop/Azure/.venv/Scripts/python.exe\" -m pip install azure-identity openai\n",
    "# !\"C:/Users/HaiderJan/OneDrive - Royal Cyber Inc/Desktop/Azure/.venv/Scripts/python.exe\" -m pip install azure-identi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa079cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "with (\n",
    "    DefaultAzureCredential() as credential,\n",
    "    AIProjectClient(endpoint=os.environ[\"AZURE_AI_PROJECTS_ENDPOINT\"], credential=credential) as project_client,\n",
    "):\n",
    "    print(project_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "with project_client.get_openai_client() as openai_client:\n",
    "    response=openai_client.responses.create(\n",
    "        model='gpt-4.1-mini',\n",
    "        input=\"Write a poem about Azure AI Foundry.\",\n",
    "        # previous_response_id=response.id,\n",
    "    )\n",
    "    \n",
    "    print(f\"Response output: {response.output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9380e",
   "metadata": {},
   "source": [
    "The .agents property on the AIPrjectslient gives you access to all agent operations. Agents can use an extension of the OPenAI protocol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e690c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent using my deployed model\n",
    "\n",
    "with (\n",
    "    DefaultAzureCredential() as credential,\n",
    "    AIProjectClient(endpoint=os.environ[\"AZURE_AI_PROJECTS_ENDPOINT\"], credential=credential) as project_client,\n",
    "):\n",
    "    with project_client.get_openai_client() as openai_client:\n",
    "        \n",
    "        agent=project_client.agents.create_version(\n",
    "            agent_name=\"haider-agent\",\n",
    "            definition=PromptAgentDefinition(\n",
    "                model='gpt-4.1-mini', instructions=\"You are a healpful assistant that answers general questions\",),\n",
    "        )\n",
    "        \n",
    "                \n",
    "        print(f\"Agent created (id: {agent.id}, name: {agent.name}, version: {agent.version})\")\n",
    "\n",
    "        conversation = openai_client.conversations.create(\n",
    "            items=[{\"type\": \"message\", \"role\": \"user\", \"content\": \"What is the size of France in square miles?\"}],\n",
    "        )\n",
    "        print(f\"Created conversation with initial user message (id: {conversation.id})\")\n",
    "\n",
    "        response = openai_client.responses.create(\n",
    "            conversation=conversation.id,\n",
    "            extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "            input=\"\",\n",
    "        )\n",
    "        print(f\"Response output: {response.output_text}\")\n",
    "\n",
    "        openai_client.conversations.items.create(\n",
    "            conversation_id=conversation.id,\n",
    "            items=[{\"type\": \"message\", \"role\": \"user\", \"content\": \"And what is the capital city?\"}],\n",
    "        )\n",
    "        print(f\"Added a second user message to the conversation\")\n",
    "\n",
    "        response = openai_client.responses.create(\n",
    "            conversation=conversation.id,\n",
    "            extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "            input=\"\",\n",
    "        )\n",
    "        print(f\"Response output: {response.output_text}\")\n",
    "        \n",
    "        response = openai_client.responses.create(\n",
    "            conversation=conversation.id,\n",
    "            extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "            input=\"\",\n",
    "        )\n",
    "        print(f\"Response output: {response.output_text}\")\n",
    "\n",
    "        openai_client.conversations.items.create(\n",
    "            conversation_id=conversation.id,\n",
    "            items=[{\"type\": \"message\", \"role\": \"user\", \"content\": \"And what is the capital city?\"}],\n",
    "        )\n",
    "        print(f\"Added a second user message to the conversation\")\n",
    "\n",
    "        response = openai_client.responses.create(\n",
    "            conversation=conversation.id,\n",
    "            extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "            input=\"\",\n",
    "        )\n",
    "        print(f\"Response output: {response.output_text}\")\n",
    "        response = openai_client.responses.create(\n",
    "            conversation=conversation.id,\n",
    "            extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "            input=\"\",\n",
    "        )\n",
    "        print(f\"Response output: {response.output_text}\")\n",
    "\n",
    "        openai_client.conversations.items.create(\n",
    "            conversation_id=conversation.id,\n",
    "            items=[{\"type\": \"message\", \"role\": \"user\", \"content\": \"And what is the capital city?\"}],\n",
    "        )\n",
    "        print(f\"Added a second user message to the conversation\")\n",
    "\n",
    "        response = openai_client.responses.create(\n",
    "            conversation=conversation.id,\n",
    "            extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "            input=\"\",\n",
    "        )\n",
    "        print(f\"Response output: {response.output_text}\")\n",
    "\n",
    "        # openai_client.conversations.delete(conversation_id=conversation.id)\n",
    "        # print(\"Conversation deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac0c7f4",
   "metadata": {},
   "source": [
    "**SAMPLE AGENT BASIC ASYNC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc7329a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: https://macarthur-foundry.services.ai.azure.com/api/projects/proj-default\n",
      "Model: gpt-4.1-mini\n",
      "Agent created (name: haider-async-agent, id: haider-async-agent:2, version: 2)\n",
      "Created conversation with initial user message (id: conv_2cdaec6a230433d700Z3EDW6UOsytwT9tusirWl2QEzvIQGf6m)\n",
      "Response output: The size of France is approximately 248,573 square miles.\n",
      "Added a second user message to the conversation\n",
      "Response output: The capital city of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "    This sample demonstrates how to run basic Prompt Agent operations\n",
    "    using the asynchronous AIProjectClient.\n",
    "\n",
    "    The OpenAI compatible Responses and Conversation calls in this sample are made using\n",
    "    the OpenAI client from the `openai` package. See https://platform.openai.com/docs/api-reference\n",
    "    for more information.\n",
    "\n",
    "USAGE:\n",
    "    python sample_agent_basic_async.py\n",
    "\n",
    "    Before running the sample:\n",
    "\n",
    "    pip install \"azure-ai-projects>=2.0.0b1\" python-dotenv aiohttp\n",
    "\n",
    "    Set these environment variables with your own values:\n",
    "    1) AZURE_AI_PROJECT_ENDPOINT - The Azure AI Project endpoint, as found in the Overview\n",
    "       page of your Microsoft Foundry portal.\n",
    "    2) AZURE_AI_MODEL_DEPLOYMENT_NAME - The deployment name of the AI model, as found under the \"Name\" column in\n",
    "       the \"Models + endpoints\" tab in your Microsoft Foundry project.\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_AI_PROJECTS_ENDPOINT\")\n",
    "model=os.getenv(\"MODEL_NAME\")\n",
    "\n",
    "print(f\"Endpoint: {endpoint}\")\n",
    "print(f\"Model: {model}\")\n",
    "\n",
    "async def main() -> None:\n",
    "    async with (\n",
    "        DefaultAzureCredential() as credential,\n",
    "        AIProjectClient(endpoint=endpoint, credential=credential) as project_client,\n",
    "        project_client.get_openai_client() as openai_client,\n",
    "    ):\n",
    "\n",
    "        agent = await project_client.agents.create_version(\n",
    "            agent_name=\"haider-async-agent\",\n",
    "            definition=PromptAgentDefinition(\n",
    "                model=model,\n",
    "                instructions=\"You are a helpful assistant that answers general questions.\",\n",
    "            ),\n",
    "        )\n",
    "        print(f\"Agent created (name: {agent.name}, id: {agent.id}, version: {agent.version})\")\n",
    "\n",
    "        conversation = await openai_client.conversations.create(\n",
    "            items=[{\"type\": \"message\", \"role\": \"user\", \"content\": \"What is the size of France in square miles?\"}],\n",
    "        )\n",
    "        print(f\"Created conversation with initial user message (id: {conversation.id})\")\n",
    "\n",
    "        response = await openai_client.responses.create(\n",
    "            conversation=conversation.id,\n",
    "            extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "            input=\"\",\n",
    "        )\n",
    "        print(f\"Response output: {response.output_text}\")\n",
    "\n",
    "        await openai_client.conversations.items.create(\n",
    "            conversation_id=conversation.id,\n",
    "            items=[{\"type\": \"message\", \"role\": \"user\", \"content\": \"And what is the capital city?\"}],\n",
    "        )\n",
    "        print(f\"Added a second user message to the conversation\")\n",
    "\n",
    "        response = await openai_client.responses.create(\n",
    "            conversation=conversation.id,\n",
    "            extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "            input=\"\",\n",
    "        )\n",
    "        print(f\"Response output: {response.output_text}\")\n",
    "\n",
    "        # await openai_client.conversations.delete(conversation_id=conversation.id)\n",
    "        # print(\"Conversation deleted\")\n",
    "\n",
    "        # await project_client.agents.delete_version(agent_name=agent.name, agent_version=agent.version)\n",
    "        # print(\"Agent deleted\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74841ae2",
   "metadata": {},
   "source": [
    "**SAMPLE AGENT BASIC RETRIEVE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde66109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved agent (name: haider-async-agent, id: haider-async-agent, version: 2)\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'code': 'invalid_parameters', 'message': 'Un-expected identitifer.', 'param': 'conversationId{resp_2cdaec6a230433d70069598c88217081908351b84466560cae}', 'type': 'invalid_request_error', 'details': [], 'additionalInfo': {'request_id': 'f528a938588c7a5ca3b8b23b7a9b1c45'}}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     34\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetrieved conversation (id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversation.id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetrieved agent (name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent.id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent.versions.latest.version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m#retrieve a stored conversation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m conversation=\u001b[38;5;28;01mawait\u001b[39;00m openai_client.conversations.retrieve(conversation_id=conversation_id)\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetrieved conversation (id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversation.id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HaiderJan\\OneDrive - Royal Cyber Inc\\Desktop\\Azure\\.venv\\Lib\\site-packages\\openai\\resources\\conversations\\conversations.py:314\u001b[39m, in \u001b[36mAsyncConversations.retrieve\u001b[39m\u001b[34m(self, conversation_id, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conversation_id:\n\u001b[32m    313\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected a non-empty value for `conversation_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversation_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get(\n\u001b[32m    315\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/conversations/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversation_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    316\u001b[39m     options=make_request_options(\n\u001b[32m    317\u001b[39m         extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m    318\u001b[39m     ),\n\u001b[32m    319\u001b[39m     cast_to=Conversation,\n\u001b[32m    320\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HaiderJan\\OneDrive - Royal Cyber Inc\\Desktop\\Azure\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1743\u001b[39m, in \u001b[36mAsyncAPIClient.get\u001b[39m\u001b[34m(self, path, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1733\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1735\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1740\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1741\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1742\u001b[39m     opts = FinalRequestOptions.construct(method=\u001b[33m\"\u001b[39m\u001b[33mget\u001b[39m\u001b[33m\"\u001b[39m, url=path, **options)\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HaiderJan\\OneDrive - Royal Cyber Inc\\Desktop\\Azure\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1597\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1594\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m err.response.aread()\n\u001b[32m   1596\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1597\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1599\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'code': 'invalid_parameters', 'message': 'Un-expected identitifer.', 'param': 'conversationId{resp_2cdaec6a230433d70069598c88217081908351b84466560cae}', 'type': 'invalid_request_error', 'details': [], 'additionalInfo': {'request_id': 'f528a938588c7a5ca3b8b23b7a9b1c45'}}}"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "agent_name = \"haider-async-agent\"\n",
    "conversation_id = os.getenv(\"CONVERSATION_ID\")\n",
    "endpoint = os.getenv(\"AZURE_AI_PROJECTS_ENDPOINT\")\n",
    "model=os.getenv(\"MODEL_NAME\")\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    \n",
    "    async with (\n",
    "        DefaultAzureCredential() as credential,\n",
    "        AIProjectClient(endpoint=endpoint, credential=credential) as project_client,\n",
    "        project_client.get_openai_client() as openai_client,\n",
    "        \n",
    "    ):\n",
    "\n",
    "        agent = await project_client.agents.get(\n",
    "            agent_name=agent_name,\n",
    "        )\n",
    "        print(f\"Retrieved agent (name: {agent.name}, id: {agent.id}, version: {agent.versions.latest.version})\")\n",
    "        \n",
    "        #retrieve a stored conversation\n",
    "        \n",
    "        conversation=await openai_client.conversations.retrieve(conversation_id='conv_2cdaec6a230433d700Z3EDW6UOsytwT9tusirWl2QEzvIQGf6m')\n",
    "        print(f\"Retrieved conversation (id: {conversation.id})\")\n",
    "        \n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
